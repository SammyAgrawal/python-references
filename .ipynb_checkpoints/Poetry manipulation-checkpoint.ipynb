{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'v']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parts_of_speech(word):\n",
    "    sys = wordnet.synsets(word)\n",
    "    pos = []\n",
    "    for i in sys:\n",
    "        pos.append(i.pos())\n",
    "    return(list(set(pos)))\n",
    "parts_of_speech('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(parts_of_speech(\"chair\"))\n",
    "cry = parts_of_speech(\"cry\")\n",
    "\"n\" in cry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frank'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getSyn(word, mypos='n'):\n",
    "    synonyms = []\n",
    "    system = wordnet.synsets(word, pos=mypos)\n",
    "    for sys in system:\n",
    "        for lem in sys.lemmas():\n",
    "            synonyms.append(lem.name())\n",
    "    synonyms = list(set(synonyms))\n",
    "    num = random.randint(0,len(synonyms)-1)\n",
    "    return(synonyms[num])\n",
    "getSyn('dog', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_nouns(words):\n",
    "    collection = words.split()\n",
    "    story = []\n",
    "    for word in collection:\n",
    "        if (word[-1] == ):\n",
    "        if(\"n\" in parts_of_speech(word)): # if the word could be a noun\n",
    "            word = getSyn(word,'n')\n",
    "        story.append(word)\n",
    "    return(\" \".join(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing out the computer_program babe'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute_nouns('testing out the program baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_verbs(words):\n",
    "    collection = words.split()\n",
    "    story = []\n",
    "    for word in collection:\n",
    "        if(\"v\" in parts_of_speech(word)): # if the word could be a noun\n",
    "            word = getSyn(word,'v')\n",
    "        story.append(word)\n",
    "    return(\" \".join(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'melt_down and veil lil boy'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute_verbs(\"run and hide lil boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi he said to the man'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nopunct(string):\n",
    "    # define punctuation\n",
    "    punctuations = '''.!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in string:\n",
    "        if(char not in punctuations):\n",
    "            no_punct = no_punct + char\n",
    "    return(no_punct)\n",
    "\n",
    "nopunct(\"hi, he. said? to/ the man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try it out!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Two roads diverged in a yellow wood\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    " \"\"\"\n",
    "text = nopunct(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 roads diverged Indiana group_A yellowness woodwind And sorry unity could not change_of_location both And Be single traveller long iodine stood And looked down single group_A Former_Armed_Forces American_Samoa one could To where information_technology knack inch the undergrowth then took the other As just a carnival And having perhaps the punter call Because IT Washington grassy and wanted wearing Though AS for that the qualifying there Had worn them really about the Saami And both that forenoon equally ballad inch parting No footstep had trodden black Buckeye_State i kept the low_gear for another daytime Yet knowing how fashion spark_advance on to agency 1 doubted if single should ever come rachis unity shall Be singing this with ampere sigh somewhere age and historic_period hence deuce route diverged in deoxyadenosine_monophosphate Natalie_Wood and I— iodin took the 1 lupus_erythematosus traveled by And that HA made all the remainder'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute_nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How synonym works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet \n",
    "synonyms = [] \n",
    "antonyms = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('good.a.01'),\n",
       " Synset('full.s.06'),\n",
       " Synset('good.a.03'),\n",
       " Synset('estimable.s.02'),\n",
       " Synset('beneficial.s.01'),\n",
       " Synset('good.s.06'),\n",
       " Synset('good.s.07'),\n",
       " Synset('adept.s.01'),\n",
       " Synset('good.s.09'),\n",
       " Synset('dear.s.02'),\n",
       " Synset('dependable.s.04'),\n",
       " Synset('good.s.12'),\n",
       " Synset('good.s.13'),\n",
       " Synset('effective.s.04'),\n",
       " Synset('good.s.15'),\n",
       " Synset('good.s.16'),\n",
       " Synset('good.s.17'),\n",
       " Synset('good.s.18'),\n",
       " Synset('good.s.19'),\n",
       " Synset('good.s.20'),\n",
       " Synset('good.s.21')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = wordnet.synsets('good', pos='s')\n",
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('good.a.01')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system[0].pos() #part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('good.a.01.good')\n",
      "Lemma('full.s.06.full')\n",
      "Lemma('full.s.06.good')\n",
      "Lemma('good.a.03.good')\n",
      "Lemma('estimable.s.02.estimable')\n",
      "Lemma('estimable.s.02.good')\n",
      "Lemma('estimable.s.02.honorable')\n",
      "Lemma('estimable.s.02.respectable')\n",
      "Lemma('beneficial.s.01.beneficial')\n",
      "Lemma('beneficial.s.01.good')\n",
      "Lemma('good.s.06.good')\n",
      "Lemma('good.s.07.good')\n",
      "Lemma('good.s.07.just')\n",
      "Lemma('good.s.07.upright')\n",
      "Lemma('adept.s.01.adept')\n",
      "Lemma('adept.s.01.expert')\n",
      "Lemma('adept.s.01.good')\n",
      "Lemma('adept.s.01.practiced')\n",
      "Lemma('adept.s.01.proficient')\n",
      "Lemma('adept.s.01.skillful')\n",
      "Lemma('adept.s.01.skilful')\n",
      "Lemma('good.s.09.good')\n",
      "Lemma('dear.s.02.dear')\n",
      "Lemma('dear.s.02.good')\n",
      "Lemma('dear.s.02.near')\n",
      "Lemma('dependable.s.04.dependable')\n",
      "Lemma('dependable.s.04.good')\n",
      "Lemma('dependable.s.04.safe')\n",
      "Lemma('dependable.s.04.secure')\n",
      "Lemma('good.s.12.good')\n",
      "Lemma('good.s.12.right')\n",
      "Lemma('good.s.12.ripe')\n",
      "Lemma('good.s.13.good')\n",
      "Lemma('good.s.13.well')\n",
      "Lemma('effective.s.04.effective')\n",
      "Lemma('effective.s.04.good')\n",
      "Lemma('effective.s.04.in_effect')\n",
      "Lemma('effective.s.04.in_force')\n",
      "Lemma('good.s.15.good')\n",
      "Lemma('good.s.16.good')\n",
      "Lemma('good.s.16.serious')\n",
      "Lemma('good.s.17.good')\n",
      "Lemma('good.s.17.sound')\n",
      "Lemma('good.s.18.good')\n",
      "Lemma('good.s.18.salutary')\n",
      "Lemma('good.s.19.good')\n",
      "Lemma('good.s.19.honest')\n",
      "Lemma('good.s.20.good')\n",
      "Lemma('good.s.20.undecomposed')\n",
      "Lemma('good.s.20.unspoiled')\n",
      "Lemma('good.s.20.unspoilt')\n",
      "Lemma('good.s.21.good')\n"
     ]
    }
   ],
   "source": [
    "for sys in system:\n",
    "    for lem in sys.lemmas():\n",
    "        print(lem)\n",
    "        synonyms.append(lem.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adept',\n",
       " 'beneficial',\n",
       " 'commodity',\n",
       " 'dear',\n",
       " 'dependable',\n",
       " 'effective',\n",
       " 'estimable',\n",
       " 'expert',\n",
       " 'full',\n",
       " 'good',\n",
       " 'goodness',\n",
       " 'honest',\n",
       " 'honorable',\n",
       " 'in_effect',\n",
       " 'in_force',\n",
       " 'just',\n",
       " 'near',\n",
       " 'practiced',\n",
       " 'proficient',\n",
       " 'respectable',\n",
       " 'right',\n",
       " 'ripe',\n",
       " 'safe',\n",
       " 'salutary',\n",
       " 'secure',\n",
       " 'serious',\n",
       " 'skilful',\n",
       " 'skillful',\n",
       " 'sound',\n",
       " 'soundly',\n",
       " 'thoroughly',\n",
       " 'trade_good',\n",
       " 'undecomposed',\n",
       " 'unspoiled',\n",
       " 'unspoilt',\n",
       " 'upright',\n",
       " 'well'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 7, 8, 45, 93]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([1,1,2,45,7,8,93,8,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ge ar gf  ae'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li= \"ge ar gf, ae\".split(',')\n",
    "\" \".join(li)\n",
    "#for word in li.split():\n",
    "#    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spell a word'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['spell', 'a', 'word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
